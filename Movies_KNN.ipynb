{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUrppziryR2jWnWR6ZR24Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EsserMishelle/DataScience/blob/main/Movies_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSuafUtJ3WiM"
      },
      "outputs": [],
      "source": [
        "from movies import movie_dataset, movie_labels, normalize_point, training_set, training_labels, validation_set, validation_labels\n",
        "\n",
        "print(movie_dataset['Bruce Almighty'])\n",
        "print(movie_labels['Bruce Almighty'])\n",
        "\n",
        "# movie_dataset[\"Bruce Almighty\"] = [0.9, 0.2, 0.8]\n",
        "# movie_labels[\"Bruce Almighty\"] = \"Comedy\" or 0 (rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gFN2RvFz4Ts6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# It computes Euclidean distance between two movies represented as vectors.\n",
        "# Mathematically:\n",
        "# movie1 and movie2 are lists of numbers\n",
        "# For each feature:\n",
        "# Subtract values\n",
        "# Square the difference\n",
        "# Add it to squared_difference\n",
        "# Take the square root at the end\n",
        "\n",
        "# Smaller distance → movies are more similar\n",
        "# Larger distance → movies are less similar\n",
        "\n",
        "def distance(movie1, movie2):\n",
        "  squared_difference = 0\n",
        "  for i in range(len(movie1)):\n",
        "    squared_difference += (movie1[i] - movie2[i]) ** 2\n",
        "  final_distance = squared_difference ** 0.5\n",
        "  return final_distance\n",
        "\n"
      ],
      "metadata": {
        "id": "s13WA1ir3fNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unknown → the movie you want to classify (a feature vector)\n",
        "# dataset → known movies with features\n",
        "# k → number of nearest neighbors to use\n",
        "\n",
        "def classify (unknown, dataset, k):\n",
        "  distances =[]\n",
        "  # This will store:\n",
        "  # [distance, movie_title] in the empty list\n",
        "\n",
        "  for title in dataset:\n",
        "  # title → movie name\n",
        "  # movie → feature vector for that movie\n",
        "    movie = dataset[title]\n",
        "\n",
        "    # call the distance function passing the movie and the unknown dataset to compare\n",
        "    distance_to_point = distance(movie, unknown)\n",
        "    distances.append([distance_to_point, title])\n",
        "  # sort by distance\n",
        "  distances.sort()\n",
        "  # return distances\n",
        "\n",
        "#  selecting only the k closest points\n",
        "  neighbors = distances[0:k]\n",
        "\n",
        "  num_good = 0\n",
        "  num_bad = 0\n",
        "\n",
        "  for movie in neighbors:\n",
        "\n",
        "    # Every neighbor is a list of [distance, title] so the title can be found at index 1.\n",
        "    title = movie[1]\n",
        "    if labels[title] == 0: # this is how we get the rating\n",
        "      num_bad += 1\n",
        "    else:\n",
        "      num_good += 1\n",
        "\n",
        "  if num_good > num_bad:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n"
      ],
      "metadata": {
        "id": "DC9oFxbT3huF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(classify([.4, .2, .9], movie_dataset, movie_labels, k=5))\n"
      ],
      "metadata": {
        "id": "tB2pbOG03k8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Call Me By Your Name\" in movie_dataset) # false\n",
        "my_movie = [3500000, 132, 2017]\n",
        "normalized_my_movie = normalize_point(my_movie)\n",
        "print(normalized_my_movie) # [0.00028650338197026213, 0.3242320819112628, 1.0112359550561798]\n",
        "\n",
        "print(classify(normalized_my_movie, movie_dataset, movie_labels, 5)) # 1"
      ],
      "metadata": {
        "id": "34ZfjpJ7CdLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We’ve imported training_set, training_labels, validation_set, and validation_labels. Let’s take a look at one of the movies in validation_set.\n",
        "\n",
        "* The movie \"Bee Movie\" is in validation_set. Print out the data associated with Bee Movie. Print Bee Movie ‘s label as well (which can be found in validation_labels)."
      ],
      "metadata": {
        "id": "QMFVyRnOFj8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(validation_set['Bee Movie']) # [0.012279463360232739, 0.18430034129692832, 0.898876404494382]\n",
        "print(validation_labels[\"Bee Movie\"]) # 0"
      ],
      "metadata": {
        "id": "FWdi_30YFUt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bee Movie‘s data can be found using validation_set[\"Bee Movie\"]. Use that as the first parameter of the classify function.\n",
        "guess = classify(validation_set['Bee Movie'],training_set, training_labels, k=5)\n",
        "print(guess) # 0\n",
        "\n",
        "if guess == validation_labels[\"Bee Movie\"]:\n",
        "  print('Correct!')\n",
        "else:\n",
        "  print('Wrong!') # Correct"
      ],
      "metadata": {
        "id": "lPfTKGnGF1Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_validation_accuracy(training_set, training_labels, validation_set, validation_labels, k):\n",
        "\n",
        "  num_correct = 0\n",
        "\n",
        "  for title in validation_set:\n",
        "    guess= classify(validation_set[title], training_set, training_labels, k)\n",
        "    if guess == validation_labels[title]:\n",
        "      num_correct +=1\n",
        "\n",
        "  return num_correct / len(validation_set)"
      ],
      "metadata": {
        "id": "Qn9gFmrQJEQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using real dataset\n",
        "from movies import movie_dataset, labels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5)\n",
        "classifier.fit(movie_dataset, labels)\n",
        "\n",
        "unknown_points = [\n",
        "  [.45, .2, .5], [.25, .8, .9], [.1, .1, .9]\n",
        "]\n",
        "guess = classifier.predict(unknown_points)\n",
        "print(guess)"
      ],
      "metadata": {
        "id": "MrnIeOGeQaMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from movies import movie_dataset, movie_ratings\n",
        "\n",
        "def distance(movie1, movie2):\n",
        "  squared_difference = 0\n",
        "  for i in range(len(movie1)):\n",
        "    squared_difference += (movie1[i] - movie2[i]) ** 2\n",
        "  final_distance = squared_difference ** 0.5\n",
        "  return final_distance\n",
        "\n",
        "def predict(unknown, dataset, movie_ratings, k):\n",
        "  distances = []\n",
        "  #Looping through all points in the dataset\n",
        "  for title in dataset:\n",
        "    movie = dataset[title]\n",
        "    distance_to_point = distance(movie, unknown)\n",
        "    #Adding the distance and point associated with that distance\n",
        "    distances.append([distance_to_point, title])\n",
        "  distances.sort()\n",
        "  #Taking only the k closest points\n",
        "  neighbors = distances[0:k]\n",
        "\n",
        "  total = 0\n",
        "  for neighbor in neighbors:\n",
        "    title = neighbor[1]\n",
        "    total += movie_ratings[title]\n",
        "\n",
        "  return total/len(neighbors)\n",
        "\n",
        "print(movie_dataset[\"Life of Pi\"]) # [0.00982356711895032, 0.30716723549488056, 0.9550561797752809]\n",
        "print(movie_ratings[\"Life of Pi\"]) # 8.0\n",
        "\n",
        "print(predict([0.016, 0.300, 1.022], movie_dataset, movie_ratings,\n",
        "k=5))\n",
        "# 6.859999999999999\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "FY8r5U2nxN6v",
        "outputId": "39045e94-5ba6-48ec-a8b8-6202405a1ba7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'movies'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2920122225.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmovies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmovie_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msquared_difference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'movies'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from movies import movie_dataset, movie_ratings\n",
        "\n",
        "def distance(movie1, movie2):\n",
        "  squared_difference = 0\n",
        "  for i in range(len(movie1)):\n",
        "    squared_difference += (movie1[i] - movie2[i]) ** 2\n",
        "  final_distance = squared_difference ** 0.5\n",
        "  return final_distance\n",
        "\n",
        "def predict(unknown, dataset, movie_ratings, k):\n",
        "  distances = []\n",
        "\n",
        "  #Looping through all points in the dataset\n",
        "  for title in dataset:\n",
        "    movie = dataset[title]\n",
        "    distance_to_point = distance(movie, unknown)\n",
        "    #Adding the distance and point associated with that distance\n",
        "    distances.append([distance_to_point, title])\n",
        "  distances.sort()\n",
        "  #Taking only the k closest points\n",
        "  neighbors = distances[0:k]\n",
        "\n",
        "  denominator = 0\n",
        "  numerator = 0\n",
        "\n",
        "  for neighbor in neighbors:\n",
        "    rating = movie_ratings[neighbor[1]]\n",
        "    distance_to_neighbor = neighbor[0]\n",
        "    numerator +=  rating/distance_to_neighbor\n",
        "    denominator += 1/neighbor[0]\n",
        "\n",
        "  return numerator/denominator\n",
        "\n",
        "print(predict([0.016, 0.300, 1.022], movie_dataset, movie_ratings, k=5)) # 6.849139678439045``\n"
      ],
      "metadata": {
        "id": "lhhXfzBJ_J35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KNeighborsRegressor class is very similar to KNeighborsClassifier.\n",
        "\n",
        "We first need to create the regressor. We can use the\n",
        "parameter\n",
        "\n",
        "\n",
        "We can also choose whether or not to use a weighted average using the parameter weights. If weights equals \"uniform\", all neighbors will be considered equally in the average. If weights equals \"distance\", then a weighted average is used."
      ],
      "metadata": {
        "id": "THjVa4DdUFzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training_points = [\n",
        "#   [0.5, 0.2, 0.1],\n",
        "#   [0.9, 0.7, 0.3],\n",
        "#   [0.4, 0.5, 0.7]\n",
        "# ]\n",
        "\n",
        "# training_labels = [5.0, 6.8, 9.0]\n",
        "# classifier.fit(training_points, training_labels)\n",
        "\n",
        "# .predict() takes a list of points and returns a list of predictions for those points.\n",
        "# unknown_points = [\n",
        "#   [0.2, 0.1, 0.7],\n",
        "#   [0.4, 0.7, 0.6],\n",
        "#   [0.5, 0.8, 0.1]\n",
        "# ]\n",
        "\n",
        "# guesses = classifier.predict(unknown_points)\n",
        "\n",
        "from movies import movie_dataset, movie_ratings\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "regressor =KNeighborsRegressor(n_neighbors = 5, weights = \"distance\")\n",
        "\n",
        "regressor.fit(movie_dataset, movie_ratings)\n",
        "# guesses = regressor.predict(unknown_points)\n",
        "\n",
        "unknown_points = [\n",
        "[0.016, 0.300, 1.022],\n",
        "[0.0004092981, 0.283, 1.0112],\n",
        "[0.00687649, 0.235, 1.0112]\n",
        "]\n",
        "\n",
        "guess = regressor.predict(unknown_points)\n",
        "print(guess) # [6.84913968 5.47572913 6.91067999]\n",
        "\n",
        "# print(regressor.predict([[0.016, 0.300, 1.022], [0.0004092981, 0.283, 1.0112], [0.00687649, 0.235, 1.0112] ]))\n"
      ],
      "metadata": {
        "id": "TZQtEUpxUYq_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}